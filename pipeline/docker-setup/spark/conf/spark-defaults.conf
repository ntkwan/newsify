# AWS S3 credentials
spark.hadoop.fs.s3a.access.key ${AWS_ACCESS_KEY_ID}
spark.hadoop.fs.s3a.secret.key ${AWS_SECRET_ACCESS_KEY}
spark.hadoop.fs.s3a.region ${AWS_DEFAULT_REGION}
spark.hadoop.fs.s3a.endpoint s3.amazonaws.com
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.impl                       org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2
spark.speculation                              false
spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain

# Delta configs
spark.databricks.delta.retentionDurationCheck.enabled false
spark.sql.extensions io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog org.apache.spark.sql.delta.catalog.DeltaCatalog

# Enable event logs 
spark.master                           spark://spark-master:7077
spark.eventLog.enabled true
spark.eventLog.dir /opt/spark/spark-events
spark.history.fs.logDirectory          /opt/spark/spark-events

# Dependencies
spark.sql.codegen.wholeStage false
spark.ui.prometheus.enabled            true
